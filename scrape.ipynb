{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape of a Wordpress site\n",
    "\n",
    "In this notebook, I attempt to scrape a wordpress site using BeautifulSoup4. The objective is to aid the production team by providing an XML or JSON file that they can in turn import into a new Wordpress site. The result will save human hours by providing a simple summary of the contents of a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First import the tools\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the page into python\n",
    "r = requests.get('http://www.heckler.com/')\n",
    "# print (r.text[0:1000]) # Verify that there is connection allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse into Beautiful Soup\n",
    "soup = bs(r.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all elements of the articles\n",
    "\n",
    "main_container = soup.find('div', attrs={'class':'cb-main'})\n",
    "results = main_container.find_all('article')\n",
    "first_result = results[0]\n",
    "title = first_result.find('h2').text\n",
    "author = ((first_result.find('div', attrs={'class':'cb-author'})).text)[1:]\n",
    "date_updated = first_result.find('time')['datetime']\n",
    "categories = (first_result.find_all('div', attrs={'class':'cb-category'}))[0].text\n",
    "url = first_result.find('a')['href']\n",
    "excerpt = (first_result.find('div', attrs={'class':'cb-excerpt'}).text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through all articles in the loaded page\n",
    "\n",
    "records = []\n",
    "for result in results:\n",
    "    \n",
    "    title = result.find('h2').text\n",
    "    author = ((result.find('div', attrs={'class':'cb-author'})).text)[1:]\n",
    "    date_updated = result.find('time')['datetime']\n",
    "    categories = (result.find_all('div', attrs={'class':'cb-category'}))[0].text\n",
    "    excerpt = result.find('div', attrs={'class':'cb-excerpt'}).text\n",
    "    url = result.find('a')['href']\n",
    "    records.append((title, author, date_updated, categories, excerpt, url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading records into a Pandas Dataframe\n",
    "\n",
    "df = pd.DataFrame(records, columns=['title', 'author', 'date_updated', 'categories', 'excerpt', 'url'])\n",
    "df['date_updated'] = pd.to_datetime(df['date_updated'])\n",
    "df.to_csv('export.csv', index=False, encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
